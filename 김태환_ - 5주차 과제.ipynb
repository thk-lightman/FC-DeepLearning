{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"김태환_ - 5주차 과제.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"5iUC91904L_F"},"source":["#5주차 과제 공지사항\n","\n","----\n","\n","1. 아래의 과제를 보고 답안을 작성하시면 됩니다.\n","2. 과제에 대한 점수는 100점 만점으로 진행이 됩니다. (한 문제당 20점)\n","3. 과제에 대한 평가는 모든 수강생들의 평가가 완료되면 확인할 수 있습니다. 참고부탁드립니다.\n","4. 과제기한은 일요일 저녁 10시 까지 입니다. 10시 이후에는 이 불가하오니 이 점 참고부탁드립니다.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PDsIxMg84Ng1"},"source":["\n","# 문제1. Norm\n","- 난이도 : 하\n","- 관련 개념 : L1 norm\n","    \n","\n","아래의 코드는 L1 norm을 사용하는 Lasso Regression의 예시이다. alpha의 변화에 따른 계수들의 변화를 설명하여라."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JkEiHOH04Lzi","executionInfo":{"status":"ok","timestamp":1627387922485,"user_tz":-540,"elapsed":1040,"user":{"displayName":"멘토송민수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsdhIkBp7o3FVVNNFthFG4yAGQXDtiB8Y_SA15eJzA5xA4xiN5ceMCX8Anyzv5jJ_GDCpwPEgQCIZ8O1EUKY3wsU9sBFSVwK6mZVJY9e5RZbO5cFdgeu2s-Bij8u9Atu4EOT6zmoNBNkUVy6U_IlbJWbS4kz2ACM1Ngrv8s2Lh7zBE-_eI7EDCDMXFrG-s9Lmi5qmbITM8-pzTtJGOrvL7oMPDXNJOjhWV_zEKpSlkV56R7Voc38tMKfzD1HHRCQ0AsDH1q4Ywzs5Y3SIbXkYcbPLszaAQq1AkIbOz_uaznQ-VPTNlZ0QnAPb4g3gW7Yag9Y4d-FGBSCBUaPioTWOCxOze1p4slC6qRNzVRT86SrDVQI9J_9WdSlu3_IJCHtyil68rQIH19Uj0-dlqAOs5MKqx5AejuMav2NcIdvEsmAgJmK8a2A1dgJJjHB_bhBurMXo_M0FgXOemkJOUGU_Z10lXFWe1kXnHG3PmeG6VM27X2fJx90LRI51KwJTe479s12qPXIYtmMQDo0NcAyvT-8L5TzJ0PAA26AXvAgmRLWS0qgodiOVU_tDP89LXt3XwC-hEfEtMeR3PoewnuR816mV7Pc7wKgJszMo8-sur3w0vBaV6MaebXtVqTrDsYkU4KWcXd3_v3XuUMIB4m-7SqLHZ0vA2m_iez_QvWWy_E0-nTutUhUw6XouJ3Vf996D2Sw_PNn2DqjOMZOnoEsGvUuipkXYzxfR1OlvZxQKykCeDdbQ8pfgXyOrN_g98WTUXnw=s64","userId":"12762505844821625936"}},"outputId":"ab6de781-eb84-478c-d99e-c6f69f005e43"},"source":["from sklearn import datasets\n","from sklearn.linear_model import Lasso\n","\n","X, y = datasets.load_diabetes(return_X_y=True)\n","\n","alpha = 0.1\n","lasso = Lasso(alpha)\n","lasso.fit(X, y)\n","print(f'alpha={alpha} : {lasso.coef_}\\n')\n","\n","alpha = 1.0\n","lasso = Lasso(alpha)\n","lasso.fit(X, y)\n","lasso.coef_\n","print(f'alpha={alpha} : {lasso.coef_}\\n')\n","\n","alpha = 10.0\n","lasso = Lasso(alpha)\n","lasso.fit(X, y)\n","lasso.coef_\n","print(f'alpha={alpha} : {lasso.coef_}\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["alpha=0.1 : [  -0.         -155.36288234  517.18201661  275.08235083  -52.54026923\n","   -0.         -210.15975349    0.          483.91440913   33.67282148]\n","\n","alpha=1.0 : [  0.          -0.         367.70185207   6.30190419   0.\n","   0.          -0.           0.         307.6057       0.        ]\n","\n","alpha=10.0 : [ 0.  0.  0.  0.  0.  0. -0.  0.  0.  0.]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"my1iPnhWDStX"},"source":["alpha는 L1 norm을 사용하는 Regularization의 계수로 파라미터의 값을 sparse하게 만든다. 따라서 alpha값이 커짐에 따라 파라미터들에 0이 많아짐을 알 수 있다.\n"]},{"cell_type":"markdown","metadata":{"id":"Lp39-Me84URK"},"source":["\n","# 문제2. Norm\n","- 난이도 : 중 \n","- 관련 개념 : L2 norm을 이용하여 Regularization\n","- 코드를 이용하여 구해주세요.\n","\n","Linear regression의 경우, 계수는 $(X^TX)^{-1}X^TY$이다. 여기에 L2 norm을 Regularization으로 사용하는 모델이 Ridge Regression이다. 아래의 코드를 참고하여  Ridge Regression의 계수를 구하라.\n","\n","- 책, 구글링을 하셔서 ridge regression 계수의 closed form으로 구하시면 됩니다.\n","- closed form에서 $\\lambda$는 5로 해주시면 됩니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4QYV6kB-3-EY","executionInfo":{"status":"ok","timestamp":1627387959371,"user_tz":-540,"elapsed":253,"user":{"displayName":"멘토송민수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsdhIkBp7o3FVVNNFthFG4yAGQXDtiB8Y_SA15eJzA5xA4xiN5ceMCX8Anyzv5jJ_GDCpwPEgQCIZ8O1EUKY3wsU9sBFSVwK6mZVJY9e5RZbO5cFdgeu2s-Bij8u9Atu4EOT6zmoNBNkUVy6U_IlbJWbS4kz2ACM1Ngrv8s2Lh7zBE-_eI7EDCDMXFrG-s9Lmi5qmbITM8-pzTtJGOrvL7oMPDXNJOjhWV_zEKpSlkV56R7Voc38tMKfzD1HHRCQ0AsDH1q4Ywzs5Y3SIbXkYcbPLszaAQq1AkIbOz_uaznQ-VPTNlZ0QnAPb4g3gW7Yag9Y4d-FGBSCBUaPioTWOCxOze1p4slC6qRNzVRT86SrDVQI9J_9WdSlu3_IJCHtyil68rQIH19Uj0-dlqAOs5MKqx5AejuMav2NcIdvEsmAgJmK8a2A1dgJJjHB_bhBurMXo_M0FgXOemkJOUGU_Z10lXFWe1kXnHG3PmeG6VM27X2fJx90LRI51KwJTe479s12qPXIYtmMQDo0NcAyvT-8L5TzJ0PAA26AXvAgmRLWS0qgodiOVU_tDP89LXt3XwC-hEfEtMeR3PoewnuR816mV7Pc7wKgJszMo8-sur3w0vBaV6MaebXtVqTrDsYkU4KWcXd3_v3XuUMIB4m-7SqLHZ0vA2m_iez_QvWWy_E0-nTutUhUw6XouJ3Vf996D2Sw_PNn2DqjOMZOnoEsGvUuipkXYzxfR1OlvZxQKykCeDdbQ8pfgXyOrN_g98WTUXnw=s64","userId":"12762505844821625936"}},"outputId":"c7ed2595-d17b-4f56-c730-2f53460c85ff"},"source":["from sklearn import datasets\n","import numpy as np\n","\n","X, y = datasets.load_diabetes(return_X_y=True)\n","\n","print(f'X의 shape = {X.shape}')\n","\n","linear_reg_coef = np.linalg.inv(np.transpose(X) @ X) @ np.transpose(X) @ y\n","print(f'Linear Regression의 계수 = {linear_reg_coef}')\n","\n","# 여기에 작성하시면 됩니다.\n","\n","import numpy as np\n","\n","def ridgeRegression(X, y, lambVal = 5):\n","    wList = []\n","    # Get normal form of `X`\n","    A = X.T @ X \n","    # Get Identity matrix\n","    I = np.eye(A.shape[0])\n","    # Get right hand side\n","    c = X.T @ y\n","\n","    # Set up equations Bw = c        \n","    lamb_I = lambVal * I\n","    B = A + lamb_I\n","    # Solve for w\n","    w = np.linalg.solve(B,c)\n","    wList.append(w)        \n","    return wList\n","ridgeRegression(X, y)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["X의 shape = (442, 10)\n","Linear Regression의 계수 = [ -10.01219782 -239.81908937  519.83978679  324.39042769 -792.18416163\n","  476.74583782  101.04457032  177.06417623  751.27932109   67.62538639]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SZOwn8mhFSnz","executionInfo":{"status":"ok","timestamp":1627727478276,"user_tz":-540,"elapsed":648,"user":{"displayName":"김태환_","photoUrl":"","userId":"09359774921737516788"}},"outputId":"c1f1b938-950f-455d-82b2-1a19d1d1c7cc"},"source":["from sklearn import datasets\n","import numpy as np\n","\n","X, y = datasets.load_diabetes(return_X_y=True)\n","\n","print(f'X의 shape = {X.shape}')\n","\n","linear_reg_coef = np.linalg.inv(np.transpose(X) @ X) @ np.transpose(X) @ y\n","print(f'Linear Regression의 계수 = {linear_reg_coef}')\n","\n","# 여기에 작성하시면 됩니다.\n","\n","import numpy as np\n","\n","def ridgeRegression(X, y, lambVal = 5):\n","    wList = []\n","    # Get normal form of `X`\n","    A = X.T @ X \n","    # Get Identity matrix\n","    I = np.eye(A.shape[0])\n","    # Get right hand side\n","    c = X.T @ y\n","\n","    # Set up equations Bw = c        \n","    lamb_I = lambVal * I\n","    B = A + lamb_I\n","    # Solve for w\n","    w = np.linalg.solve(B,c)\n","    wList.append(w)        \n","    return wList\n","print(f'Ridege Regression의 계수 = {ridgeRegression(X, y)[0]}' )\n","# np.linalg.solve(X.T @ X, X.T @ y)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["X의 shape = (442, 10)\n","Linear Regression의 계수 = [ -10.01219782 -239.81908937  519.83978679  324.39042769 -792.18416163\n","  476.74583782  101.04457032  177.06417623  751.27932109   67.62538639]\n","Ridege Regression의 계수 = [ 28.2734378   -9.31660486 127.13955249  90.64316241  25.3963065\n","  14.03869314 -76.24920646  73.17509758 115.42308486  68.40674998]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([ -10.01219782, -239.81908937,  519.83978679,  324.39042769,\n","       -792.18416163,  476.74583782,  101.04457032,  177.06417623,\n","        751.27932109,   67.62538639])"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"O4qB6UsF4boG"},"source":["\n","# 문제3. 조기종료\n","- 난이도 : 하\n","- 관련 개념 : 조기종료 알고리즘을 만든다.\n","- 코드를 통해 풀어주세요.\n","\n","아래 주석이 있는 부분에 조기종료(early stopping)을 실행하는 코드를 작성하시오.\n","\n","- 조기종료를 하는 방법은 다양합니다.\n","- 이 문제에서는 `val_error`가  `2170000.0` 보다 작으면 조기종료가 되도록 코드를 작성해주세요.\n"]},{"cell_type":"code","metadata":{"id":"qBbbnoth4bbo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627728056218,"user_tz":-540,"elapsed":414,"user":{"displayName":"김태환_","photoUrl":"","userId":"09359774921737516788"}},"outputId":"c7960ddd-94c5-49e2-b064-f880c931152c"},"source":["from sklearn import datasets\n","import numpy as np\n","\n","X, y = datasets.load_diabetes(return_X_y=True)\n","\n","train_x = X[:300,0]\n","train_y = y[:300]\n","val_x = X[300:,0]\n","val_y = y[300:]\n","\n","a = 10\n","learning_rate = 0.05\n","n_iter = 500\n","\n","for i in range(n_iter):\n","    a = a - learning_rate * np.sum( - train_x * (train_y - a * train_x))\n","    train_error = 0.5 * np.sum((train_y - a * train_x)**2)\n","    val_error = 0.5 * np.sum((val_y - a * val_x)**2)\n","    # 여기에 early stopping 과정 작성\n","    if val_error < 2170000 : \n","      print(val_error)\n","      break\n","\n","\n","    if (i + 1) % 10 == 0:\n","        print(f'Iteration {i + 1}')\n","        print(f'train error = {train_error:.3f}')\n","        print(f'a = {a:.3f}\\n')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Iteration 10\n","train error = 4231374.283\n","a = 56.426\n","\n","Iteration 20\n","train error = 4229299.489\n","a = 88.751\n","\n","2169810.99046794\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3wW9XOjf4iaU"},"source":["\n","# 문제4. Noise\n","- 난이도 : 하 \n","- 관련 개념 : nosie를 추가하여 모델링해보기\n","\n","아래의 Linear Regression 모델링 코드를 이용하여 input X에 noise를 추가하여 test dataset의 MSE를 구하여라.\n","\n","- noise는 `np.random.normal`을 이용하여 `X_train.shape`만큼 만들어서 기존 `X`에 더한다. 이 때 `loc=0.0, scale=0.05`의 분포에서 noise를 만든다.\n"]},{"cell_type":"code","metadata":{"id":"FPsa0SU04c-i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627728210563,"user_tz":-540,"elapsed":652,"user":{"displayName":"김태환_","photoUrl":"","userId":"09359774921737516788"}},"outputId":"3e01ac6c-95d0-4e70-e9ec-fe74c4b226ca"},"source":["from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from sklearn.linear_model import LinearRegression\n","import numpy as np\n","\n","X, y = datasets.load_diabetes(return_X_y=True)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n","\n","# noise를 추가하지 않고 모델링한 예시\n","model =  LinearRegression()\n","model.fit(X_train, y_train)\n","pred = model.predict(X_test)\n","test_mse = mean_squared_error(pred, y_test)\n","\n","# 여기에 코드 작성\n","noised_X_train = X_train + np.random.normal(loc = 0.0, scale = 0.05, size = X_train.shape)\n","model.fit(noised_X_train, y_train)\n","pred = model.predict(X_test)\n","test_mse = mean_squared_error(pred, y_test)\n","print(test_mse)\n","\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["3226.9793855872294\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C1gZH-kG4khx"},"source":["\n","# 문제5. 앙상블 (Ensemble)\n","- 난이도 : 하\n","- 관련 개념 : Bagging의 개념이해\n","- 코드를 통해 풀어주세요.\n","\n","심층이는 수업시간에 배운 앙상블기법들 중에 Bagging의 기법을 사용해보고자 한다. 회귀문제에서 다양한 모델을 만든 후에 예측값들을 평균내어서 최종결과가 더 좋아지는지 비교하려고 한다. 단일 모델과 앙상블한 모델의 test mse 를 구하고 비교하여라.\n","\n","- 단일 모델 : `Lasso`\n","- 앙상블 모델 : `LinearRegression + Ridge + Lasso`\n","- 모델링에서 모델들의 hypterparameter는 default값을 이용하시면 됩니다.\n"]},{"cell_type":"code","metadata":{"id":"lRlXwwSm4kx8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627728627370,"user_tz":-540,"elapsed":386,"user":{"displayName":"김태환_","photoUrl":"","userId":"09359774921737516788"}},"outputId":"5cc9e6bc-b289-47ba-d7df-b109ea35d435"},"source":["from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso\n","\n","X, y = datasets.load_diabetes(return_X_y=True)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","linear_model = LinearRegression()\n","ridge_model = Ridge()\n","lasso_model = Lasso()\n","\n","# 모델 fit\n","linear_model.fit(X_train, y_train)\n","linear_pred = linear_model.predict(X_test)\n","\n","ridge_model.fit(X_train, y_train)\n","ridge_pred = ridge_model.predict(X_test)\n","\n","lasso_model.fit(X_train, y_train)\n","lasso_pred = lasso_model.predict(X_test)\n","\n","# 이후 과정을 코드로 작성하시면 됩니다\n","\n","test_mse = mean_squared_error(lasso_pred, y_test)\n","bagging_test_mse = mean_squared_error( sum([linear_pred, ridge_pred, lasso_pred ])/3, y_test)\n","\n","print(f'단일 모델 : {test_mse}, 앙상블 모델: {baggin_test_mse}')\n","result = abs(test_mse - baggin_test_mse)\n","result_name = '앙상블' if test_mse > bagging_test_mse else 'Lasso'\n","\n","print(f'{result_name}모델이 {result}만큼 오차가 더 적다')\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["단일 모델 : 3403.5701919165826, 앙상블 모델: 2940.457610346762\n","앙상블모델이 463.1125815698206만큼 오차가 더 적다\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HvZCf7n_L17H"},"source":[""],"execution_count":null,"outputs":[]}]}